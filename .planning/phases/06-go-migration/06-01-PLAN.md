---
phase: 06-go-migration
plan: 01
type: execute
wave: 1
depends_on: ["05-03"]
files_modified:
  - go.mod
  - go.sum
  - cmd/bansho/main.go
  - internal/config/config.go
  - internal/storage/postgres.go
  - internal/storage/redis.go
  - internal/storage/schema.go
  - internal/auth/hash.go
  - internal/auth/api_keys.go
  - internal/policy/models.go
  - internal/policy/loader.go
  - internal/ratelimit/limiter.go
  - internal/audit/models.go
  - internal/audit/logger.go
  - internal/ui/dashboard.go
  - internal/proxy/upstream.go
  - internal/proxy/server.go
  - demo/vulnerable_server_go.go
  - demo/run_before_after.sh
  - README.md
autonomous: true

must_haves:
  truths:
    - "Go binary bansho exists and can be used as the primary entrypoint"
    - "Gateway preserves auth -> authz -> rate limit -> audit -> forward behavior"
    - "YAML policy config and Redis fixed-window rate limiting are preserved"
    - "Postgres audit storage and dashboard API are preserved"
    - "Demo runner still shows 401/403/429/200 and audit evidence"
  artifacts:
    - path: cmd/bansho/main.go
      provides: "Go bansho CLI + server entrypoint"
    - path: internal/proxy/server.go
      provides: "MCP gateway server"
    - path: demo/run_before_after.sh
      provides: "Deterministic before/after demo runner (Go)"
---

<objective>
Migrate the Python implementation to the "perfect" stack: Go + official MCP Go SDK.

Preserve the existing product surface (gateway pipeline, key CLI, YAML policy, Redis fixed-window limiter, Postgres audit log, dashboard API, demo runner).
Definition of done: `go test ./...` passes and demo runner has at least one integration test path.
</objective>

<execution_context>
@/home/ubuntu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@README.md
@docker-compose.yml
@demo/run_before_after.sh
@src/bansho/proxy/bansho_server.py
@src/bansho/middleware/auth.py
@src/bansho/middleware/authz.py
@src/bansho/middleware/rate_limit.py
@src/bansho/audit/logger.py
@src/bansho/ui/dashboard.py
@src/bansho/auth/hash.py
@src/bansho/auth/api_keys.py
@src/bansho/storage/schema.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Go module scaffold + bansho CLI skeleton</name>
  <files>go.mod
go.sum
cmd/bansho/main.go
internal/config/config.go</files>
  <action>
Create a Go module and the `bansho` CLI entrypoint with subcommands:
- `bansho serve` (stdio MCP gateway)
- `bansho dashboard` (audit dashboard HTTP server)
- `bansho keys create|list|revoke` (API key lifecycle)

Load config from env vars with the same names and defaults as Python:
- BANSHO_LISTEN_HOST/BANSHO_LISTEN_PORT
- DASHBOARD_HOST/DASHBOARD_PORT
- UPSTREAM_TRANSPORT (stdio|http), UPSTREAM_CMD, UPSTREAM_URL
- POSTGRES_DSN, REDIS_URL

Support optional `.env` loading (best-effort) to preserve local workflows.
  </action>
  <verify>go test ./... || true</verify>
  <done>Go module exists, CLI compiles (even if not fully functional yet), and settings resolution is deterministic.</done>
</task>

<task type="auto">
  <name>Task 2: Storage layer (Postgres + Redis) and schema bootstrap</name>
  <files>internal/storage/postgres.go
internal/storage/redis.go
internal/storage/schema.go</files>
  <action>
Implement:
- Postgres pool creation using POSTGRES_DSN; provide `EnsureSchema()` with idempotent schema bootstrap matching Python tables (`api_keys`, `audit_events`).
- Redis client creation using REDIS_URL; provide ping and an eval helper for Lua scripts.

Keep schema compatible with existing `docker-compose.yml` defaults (5433, 6379).
  </action>
  <verify>go test ./...</verify>
  <done>Schema bootstrap works against local docker Postgres and Redis client can ping.</done>
</task>

<task type="auto">
  <name>Task 3: API key hashing + key lifecycle CLI parity</name>
  <files>internal/auth/hash.go
internal/auth/api_keys.go
cmd/bansho/main.go</files>
  <action>
Implement PBKDF2-SHA256 hashing compatible with Python format:
`pbkdf2_sha256$iterations$salt_b64$digest_b64`.

Implement key lifecycle operations:
- Create (uuid id, role default=readonly, print api_key_id + api_key once)
- List (tabular: api_key_id role revoked)
- Revoke (idempotent revoke by UUID)

Auth resolution behavior: scan non-revoked keys and verify hash (optimized index is out of scope).
  </action>
  <verify>go test ./...</verify>
  <done>`bansho keys create|list|revoke` functions match the Python outputs and semantics.</done>
</task>

<task type="auto">
  <name>Task 4: YAML policy models + loader parity</name>
  <files>internal/policy/models.go
internal/policy/loader.go</files>
  <action>
Implement YAML policy parsing compatible with current schema:
- roles: {admin,user,readonly} allow lists
- rate_limits: per_api_key + per_tool default/overrides

Fail closed on missing/invalid policy. Keep BANSHO_POLICY_PATH override with `config/policies.yaml` default.
  </action>
  <verify>go test ./...</verify>
  <done>Policy loader supports existing `demo/policies_demo.yaml` and preserves deny-by-default semantics.</done>
</task>

<task type="auto">
  <name>Task 5: Redis fixed-window rate limiting parity</name>
  <files>internal/ratelimit/limiter.go</files>
  <action>
Implement fixed-window limiter parity with Python:
- Lua `INCR` + `EXPIRE` keyed by `rl:{api_key_id}:{window_bucket}` and `rl:{api_key_id}:{tool}:{window_bucket}`
- reset seconds computed as time until next window boundary
- enforce both per-api-key and per-tool limits, raising MCP error code 429 on first exceeded dimension
  </action>
  <verify>go test ./...</verify>
  <done>Limiter behavior matches: remaining counters and reset windows are deterministic.</done>
</task>

<task type="auto">
  <name>Task 6: Audit logging + dashboard HTTP API parity</name>
  <files>internal/audit/models.go
internal/audit/logger.go
internal/ui/dashboard.go
cmd/bansho/main.go</files>
  <action>
Implement:
- AuditEvent model with bounded/sanitized JSON payloads
- AuditLogger writing to Postgres `audit_events`
- Dashboard server providing:
  - `/api/events` (JSON, supports limit/api_key_id/tool_name filters)
  - `/dashboard` (simple HTML)
Dashboard auth: require API key and allow admin role only; accept API key via Bearer, X-API-Key header, or api_key query param.
  </action>
  <verify>go test ./...</verify>
  <done>Dashboard API returns events with admin credentials and returns 401/403 appropriately.</done>
</task>

<task type="auto">
  <name>Task 7: MCP gateway proxy (auth -> authz -> rate limit -> audit -> forward)</name>
  <files>internal/proxy/upstream.go
internal/proxy/server.go
cmd/bansho/main.go</files>
  <action>
Implement MCP gateway server using the official MCP Go SDK:
- Connect to upstream MCP server (stdio via command; http via URL) and initialize.
- List tools: require auth, then filter upstream tools by authz allow-list.
- Call tool: enforce pipeline auth -> authz -> rate limit -> forward.
- Always attempt audit write in a defer/finally equivalent (one audit attempt per tools/call).
- Preserve error codes/messages for 401/403/429 and safe 500/502 payload shape.
  </action>
  <verify>go test ./...</verify>
  <done>Gateway starts as an MCP stdio server and forwards upstream tool calls while enforcing security gates.</done>
</task>

<task type="auto">
  <name>Task 8: Go demo server + updated before/after runner</name>
  <files>demo/vulnerable_server_go.go
demo/run_before_after.sh
README.md</files>
  <action>
Replace demo flow to use Go binaries:
- Provide a vulnerable MCP server (stdio) that exposes at least:
  - `list_customers` (harmless)
  - `delete_customer` (sensitive)
- Update `demo/run_before_after.sh` to:
  - start docker deps
  - run before-state attack (unauthorized sensitive call succeeds against vulnerable server)
  - create deterministic readonly/admin keys via `bansho keys create`
  - run after-state assertions (401/403/429/200) by talking to `bansho serve` over stdio
  - assert audit count increases and dashboard returns events

Update README Quickstart + Testing sections to Go workflow.
  </action>
  <verify>bash demo/run_before_after.sh</verify>
  <done>Demo runner works end-to-end without Python tooling and is easy to narrate.</done>
</task>

<task type="auto">
  <name>Task 9: Go tests + at least one integration test path for demo runner</name>
  <files>internal/**
demo/**</files>
  <action>
Add Go tests to cover critical parity:
- Unit tests for hashing format + verification
- Unit tests for policy parsing

Add an integration test path for the demo runner that is safe in CI/local:
- A Go test that runs the demo runner (or its core after-state scenario) if docker is available; otherwise it should skip cleanly.
  </action>
  <verify>go test ./...</verify>
  <done>`go test ./...` passes and includes a demonstrable integration test path (skipping only when prerequisites are absent).</done>
</task>

</tasks>

<verification>
- `go test ./...`
- `bash demo/run_before_after.sh`
</verification>

<success_criteria>
- Go `bansho` binary is the primary workflow.
- Demo runner still produces 401/403/429/200 and shows audit evidence.
</success_criteria>

<output>
After completion, create `.planning/phases/06-go-migration/06-01-SUMMARY.md`
</output>
